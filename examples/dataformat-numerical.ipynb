{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6426c30b-df03-46a9-8fb7-57ddf404683e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lagrangian simulation sample file\n",
    "\n",
    "In this Notebook, we use a simple output file from a Lagrangian simulation to highlight the required steps to convert a dataset into the ragged array format which is used by the *CloudDrift* library. The example dataset we use here comes in a format that is very closed to the output format of [Ocean Parcels](https://oceanparcels.org/) and [OpenDrift](https://opendrift.github.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cca829b-f96f-4e09-bfbc-d7b2ec2d008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from clouddrift import RaggedArray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aded949-7d07-47fd-b184-50574c2600ba",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5502078d-bf13-43b1-abce-e562eeeb73df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isfile, join, exists\n",
    "import urllib.request\n",
    "\n",
    "folder = \"../data/raw/numerical/\"\n",
    "file = \"example.nc\"\n",
    "os.makedirs(folder, exist_ok=exists(folder))  # create raw data folder\n",
    "\n",
    "if not isfile(join(folder, file)):\n",
    "    url = \"https://zenodo.org/record/6310460/files/global-marine-litter-2021.nc\"\n",
    "    print(f\"Downloading ~1.1GB from {url}.\")\n",
    "    req = urllib.request.urlretrieve(url, join(folder, file))\n",
    "    print(f\"Dataset saved at {join(folder, file)}\")\n",
    "else:\n",
    "    print(f\"Dataset already at {join(folder, file)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4da2c5-595a-48b1-b3bd-d862983a9830",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Numerical outputs from Lagrangian simulations are usually stored as bidimensional matrices. This particular example contains 387,600 trajectories saved at daily intervals during the year 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a861768-811c-4919-9096-307068871b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(join(folder, file), decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf694989-a8da-471d-89b1-f8786fc042b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197e482c-8970-4664-b65b-04254ac26a19",
   "metadata": {},
   "source": [
    " At the beginning of each month, 32,300 particles are released, and trajectories are padded with `nan` before their release date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb4a0c0-c732-465b-964a-1a7e5638f280",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.lon[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d77dfd-af3a-4902-9b7c-c71732c9e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.lon[32300,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674147bf-93fd-4636-9c95-8d2460982b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be4280a-78f9-4e7a-986b-cf64642e9e72",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "To re-organize the data into a ragged array, it is possible to create a preprocessing function and use the `RaggedArray.from_files()` class method, similarly to what is presented in the notebook example `dataformat-gdp.ipynb`. A *much faster* alternative solution for numerical simulations is to manually create the required dictionnaires to hold the dataset and to create the ragged array instance directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28276620-04de-4e73-a367-d7e8d1c5690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialized dictionnaries\n",
    "coords = {}\n",
    "metadata = {}\n",
    "# note that this example dataset does not contain other data than time, lon, lat, and ids \n",
    "# an empty dictionary \"data\" is initialize anyway\n",
    "data = {}\n",
    "attrs_global = {}\n",
    "attrs_variables = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59137333-eed9-406f-8af2-e3a782fad210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode_times=False to get time data and not datetime conversion\n",
    "ds = xr.open_dataset(join(folder, file), decode_times=False)\n",
    "\n",
    "finite_values = np.isfinite(ds['lon'])\n",
    "idx_finite = np.where(finite_values)\n",
    "\n",
    "rowsize = np.bincount(idx_finite[0]).astype('int32')\n",
    "unique_id = np.unique(idx_finite[0]).astype('int32')\n",
    "\n",
    "# coordinates\n",
    "coords[\"time\"] = np.tile(ds.time.data, (ds.dims['traj'],1))[idx_finite]  # reshape to 2D to get ragged time\n",
    "coords[\"lon\"] = ds.lon.data[idx_finite].astype('float32')\n",
    "coords[\"lat\"] = ds.lat.data[idx_finite].astype('float32')\n",
    "coords[\"ids\"] = np.repeat(unique_id, rowsize)\n",
    "\n",
    "# metadata variables\n",
    "metadata[\"rowsize\"] = rowsize\n",
    "metadata[\"ID\"] = unique_id\n",
    "\n",
    "# attributes for each variable\n",
    "attrs_variables = {\n",
    "    \"ID\": {'long_name': 'Trajectory id', 'units':'-'},\n",
    "    \"time\": {'long_name': 'Time in days', 'units': 'days since 2021-01-01'}, \n",
    "    \"lon\": {'long_name': 'longitude', 'units': 'degrees_east'}, \n",
    "    \"lat\": {'long_name': 'latitude', 'units': 'degrees_north'}, \n",
    "    \"ids\": {'long_name': 'Trajectory identification number repeated along observations', 'units': '-'},\n",
    "    \"rowsize\": {'long_name': 'Number of observations per trajectory', 'sample_dimension': 'obs', 'units':'-'},\n",
    "}\n",
    "\n",
    "# \n",
    "attrs_global={\n",
    "    'title': 'Marine Litter 2021',\n",
    "    'institution': 'Florida State University Center for Ocean-Atmospheric Prediction Studies (COAPS)'\n",
    "}\n",
    "\n",
    "ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dead30-677b-4c31-9639-c6bff150c57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = RaggedArray(coords, metadata, data, attrs_global, attrs_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00705eef-eb9b-4cdd-958d-e9afb832e7f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e377c2-2fba-4378-8c77-4f6747fa51f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra.to_parquet('../data/process/numerical_sample.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d88f4e-56d3-476c-8bc9-0ee50588a809",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32438f6c-6109-4ada-b308-b459d7aedb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra2 = RaggedArray.from_parquet('../data/process/numerical_sample.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cec59e-81f1-4c60-8bb2-9764799297e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f926f362-8f2b-491c-91e9-2bc977566a09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('clouddrift')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "51ed1a8a4b19d726e23a411b59608ec9427d5c3497f9219a586b5cd79201b8af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
