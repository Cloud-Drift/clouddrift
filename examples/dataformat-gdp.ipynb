{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6426c30b-df03-46a9-8fb7-57ddf404683e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Global Drifter Program (GDP)\n",
    "\n",
    "As part of this Notebook, we will use the *GDP historical dataset* to highlight the required steps to preprocess and dataset into a format that can be ingest by the *CloudDrift* library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d4c013-74b6-4444-828c-b74d6231141a",
   "metadata": {},
   "source": [
    "## Dataformat module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5e2a1a-2e8c-464f-8075-357c9b8313c2",
   "metadata": {},
   "source": [
    "The `dataformat.py` module contains the class `create_ragged_array` to transform a series of archives into an *Awkward Array* where all variables is stored as a *ragged array*. The module also contains `read_from_netcdf` and `read_from_parquet` to initialize the *Awkward Array* directly from an previously preprocessed archive. Right now, it *only* supports local array but we will soon add the possibility of *lazy-loading* array stored in the Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cca829b-f96f-4e09-bfbc-d7b2ec2d008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6af3634f-be14-43af-8092-8be2c95ebc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../')\n",
    "from clouddrift import dataformat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665b9136-d79f-49e7-9bf8-12ea494cf196",
   "metadata": {},
   "source": [
    "The main class of this module is *create_ragged_array* and is used to create a single archive that can be saved to a netCDF or Parquet file. The signature of the class is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95c32a79-e643-45d4-810f-f93d923e5d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mdataformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_ragged_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mindices\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpreprocess_func\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvars_coords\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvars_meta\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvars_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrowsize_func\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m           ~/Library/CloudStorage/OneDrive-FloridaStateUniversity/projects/clouddrift/clouddrift/dataformat.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataformat.create_ragged_array?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aded949-7d07-47fd-b184-50574c2600ba",
   "metadata": {},
   "source": [
    "## Dataset-specific functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c133b096-ee61-4018-b797-d43cc9db7329",
   "metadata": {},
   "source": [
    "Since each dataset is different, we have to create specific functions to preprocess the dataset (`preprocess_func`) and return the metadata and data of a single trajectory. This was inspired by the [Pangeo Forge](https://pangeo-forge.readthedocs.io/en/latest/) project. The class *create_ragged_array* will use those functions to create the single archive of ragged arrays. More precisely, it requires:\n",
    "- a list of indices (or identification number) that will be concatenate into the ragged array format\n",
    "- a dictionnary mapping the mandatory coordinates list to the name of those variables in the dataset, e.g.\n",
    "    coords = {'ids': 'number', 'time': 't', 'longitude': 'lon', 'latitude': 'lat'}\n",
    "- a list of variable names containing metadata information about the trajectory (size: 1 per trajectory)\n",
    "- a list of variable names containing the data along the trajectory (size: number of observations per trajectory)\n",
    "- a preprecessing function with the following signature:\n",
    "    - `Signature: preprocess_func(index: int) -> xarray.core.dataset.Dataset`, where the index parameter is an identifier of a trajectory, e.g. the identification number of an Argo float) and returns an *xarray Dataset*. \n",
    "    \n",
    "This function can performs all type of operations, such as formatting the date, changing the type of variables, modifying the metadata, etc. We provide preprocessing function for different datasets in the `data/recipes/` folder. The class also needs to *initially* calculate the sum of all observations. By default, this is performed using `lambda i: self.preprocess_func(i).dims['obs']`. To *speed up* this process, in the situation where a lot of preprocessing are performed, it is possible to provide a second function `rowsize_func`, that returns directly the number of observation of a trajectory (`Signature: rowsize_func(index: int) -> int`)\n",
    "\n",
    "Finally, we import the gdp module which contains a function to download (or update) and preprocess the GDP dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50aa29c2-5cfa-4ca7-ada3-7c3a6ec3b384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import gdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42a0c03-fcb3-4131-af3c-e6e7bea4e833",
   "metadata": {},
   "source": [
    "# Download\n",
    "\n",
    "The download function will store the raw dataset into the `data/raw/` folder specified in the `gdp.py` module. By default `download_gdp_data()` will download the complete GPD dataset (containing 17,324 files as of May 2022) from the AOML `https` server.\n",
    "\n",
    "**Note**: this Notebook is very similar to the `data-glad.ipynb` Notebook because very few functions have to be created to transform a new dataset. We hope that this will encourage people to use this dataformat and utilize the CloudDrift library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff938826-a6af-4e18-b8b1-39d236c92608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mgdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrifter_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_random_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Download individual netCDF files from the AOML server\n",
       "\n",
       ":param drifter_ids [list]: list of drifter to retrieve (Default: all)\n",
       ":param n_random_id [int]: randomly select n drifter netCDF files\n",
       ":return drifters_ids [list]: list of retrived drifter\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Library/CloudStorage/OneDrive-FloridaStateUniversity/projects/clouddrift/data/gdp.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gdp.download?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d977de-6162-4f63-b576-e9377d1d4f3e",
   "metadata": {},
   "source": [
    "It is possible to prodive a list of `drifter_ids` to retrieve a subset and/or specified a integer `n_random_id` to randomly retrieve `n` trajectory. The function returns the list of `drifters_ids` that was downloaded, and can be passed to create the ragged array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b162c91d-fc2a-4a86-9a0d-361e3af89b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 757094.58it/s]\n"
     ]
    }
   ],
   "source": [
    "drifter_ids = gdp.download(n_random_id=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35f6f75-f7fb-4ba3-814f-46e3b8cc7d34",
   "metadata": {},
   "source": [
    "Once the data downloaded, it is possible to create the ragged array and either save a netCDF, parquet file, or simply output an Awkward Array that can be used for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59137333-eed9-406f-8af2-e3a782fad210",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating the number of observations: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 65.35it/s]\n",
      "/Users/pmiron/miniforge3/envs/clouddrift/lib/python3.9/site-packages/xarray/coding/variables.py:140: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  condition |= data == fv\n",
      "Filling the ragged array: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 35.35it/s]\n"
     ]
    }
   ],
   "source": [
    "coords = {'ids': 'ids', 'time': 'time', 'lon': 'longitude', 'lat': 'latitude'}\n",
    "metadata = ['ID', 'rowsize', 'WMO', 'expno', 'deploy_date', 'deploy_lat', 'deploy_lon', 'end_date', 'end_lat', 'end_lon', 'drogue_lost_date', 'typedeath', 'typebuoy', 'location_type', 'DeployingShip', 'DeploymentStatus', 'BuoyTypeManufacturer', 'BuoyTypeSensorArray', 'CurrentProgram', 'PurchaserFunding', 'SensorUpgrade', 'Transmissions', 'DeployingCountry', 'DeploymentComments', 'ManufactureYear', 'ManufactureMonth', 'ManufactureSensorType', 'ManufactureVoltage', 'FloatDiameter', 'SubsfcFloatPresence', 'DrogueType', 'DrogueLength', 'DrogueBallast', 'DragAreaAboveDrogue', 'DragAreaOfDrogue', 'DragAreaRatio', 'DrogueCenterDepth', 'DrogueDetectSensor']\n",
    "data = ['ve', 'vn', 'err_lat', 'err_lon', 'err_ve', 'err_vn', 'gap', 'sst', 'sst1', 'sst2', 'err_sst', 'err_sst1', 'err_sst2', 'flg_sst', 'flg_sst1', 'flg_sst2', 'drogue_status']\n",
    "\n",
    "ra = dataformat.create_ragged_array(drifter_ids,\n",
    "                         gdp.preprocess,\n",
    "                         coords, \n",
    "                         metadata, \n",
    "                         data,\n",
    "                         rowsize_func=gdp.rowsize\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00705eef-eb9b-4cdd-958d-e9afb832e7f0",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24e377c2-2fba-4378-8c77-4f6747fa51f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ra.to_parquet('../data/process/gdp_v2.00.parquet')\n",
    "ra.to_netcdf('../data/process/gdp_v2.00.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9048e0-fc3b-49ec-b35b-285fbecda8e5",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "821a999d-ee63-4087-92e8-5373d5c61b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = dataformat.read_from_parquet('../data/process/gdp_v2.00.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e2f211d-7217-4964-bbe8-b47d93533ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Array [6428, 13566, ..., 67772920, 68246720] type='100 * int64[parameters=...'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds2.ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcf518d-1f87-44ae-a284-7a4b34950bbc",
   "metadata": {},
   "source": [
    "## Awkward Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d885008c-c033-4532-a356-10055ae774a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward._v2 as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7334d731-4bfd-4e29-9196-bd68953df007",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ra.to_awkward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e2b66fb-beb6-4316-8af1-b14a6029e3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Array [0.00384, 0.00278, ..., 0.00042, 0.000402] type='100 * ?float64'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ak.nanmean(ds.obs.err_lat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58b48833-387a-4fe7-a144-1e1628959ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID',\n",
       " 'rowsize',\n",
       " 'WMO',\n",
       " 'expno',\n",
       " 'deploy_date',\n",
       " 'deploy_lat',\n",
       " 'deploy_lon',\n",
       " 'end_date',\n",
       " 'end_lat',\n",
       " 'end_lon',\n",
       " 'drogue_lost_date',\n",
       " 'typedeath',\n",
       " 'typebuoy',\n",
       " 'location_type',\n",
       " 'DeployingShip',\n",
       " 'DeploymentStatus',\n",
       " 'BuoyTypeManufacturer',\n",
       " 'BuoyTypeSensorArray',\n",
       " 'CurrentProgram',\n",
       " 'PurchaserFunding',\n",
       " 'SensorUpgrade',\n",
       " 'Transmissions',\n",
       " 'DeployingCountry',\n",
       " 'DeploymentComments',\n",
       " 'ManufactureYear',\n",
       " 'ManufactureMonth',\n",
       " 'ManufactureSensorType',\n",
       " 'ManufactureVoltage',\n",
       " 'FloatDiameter',\n",
       " 'SubsfcFloatPresence',\n",
       " 'DrogueType',\n",
       " 'DrogueLength',\n",
       " 'DrogueBallast',\n",
       " 'DragAreaAboveDrogue',\n",
       " 'DragAreaOfDrogue',\n",
       " 'DragAreaRatio',\n",
       " 'DrogueCenterDepth',\n",
       " 'DrogueDetectSensor',\n",
       " 'obs']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4b78c8a-177b-4842-a8c9-9f98daaa27e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ids',\n",
       " 'time',\n",
       " 'lon',\n",
       " 'lat',\n",
       " 've',\n",
       " 'vn',\n",
       " 'err_lat',\n",
       " 'err_lon',\n",
       " 'err_ve',\n",
       " 'err_vn',\n",
       " 'gap',\n",
       " 'sst',\n",
       " 'sst1',\n",
       " 'sst2',\n",
       " 'err_sst',\n",
       " 'err_sst1',\n",
       " 'err_sst2',\n",
       " 'flg_sst',\n",
       " 'flg_sst1',\n",
       " 'flg_sst2',\n",
       " 'drogue_status']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.obs.fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2848fc27-2151-40e3-9dda-6746df5a2ec6",
   "metadata": {},
   "source": [
    "### global attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cfc0238-1bab-4bf4-994d-459231fb5f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attrs': {'title': 'Global Drifter Program hourly drifting buoy collection',\n",
       "  'history': 'Version 2.00.  Metadata from dirall.dat and deplog.dat',\n",
       "  'Conventions': 'CF-1.6',\n",
       "  'date_created': '2022-05-31T16:41:40.747570',\n",
       "  'publisher_name': 'GDP Drifter DAC',\n",
       "  'publisher_email': 'aoml.dftr@noaa.gov',\n",
       "  'publisher_url': 'https://www.aoml.noaa.gov/phod/gdp',\n",
       "  'licence': 'MIT License',\n",
       "  'processing_level': 'Level 2 QC by GDP drifter DAC',\n",
       "  'metadata_link': 'https://www.aoml.noaa.gov/phod/dac/dirall.html',\n",
       "  'contributor_name': 'NOAA Global Drifter Program',\n",
       "  'contributor_role': 'Data Acquisition Center',\n",
       "  'institution': 'NOAA Atlantic Oceanographic and Meteorological Laboratory',\n",
       "  'acknowledgement': 'Elipot et al. (2022) to be submitted. Elipot et al. (2016). Global Drifter Program quality-controlled hourly interpolated data from ocean surface drifting buoys, version 2.00. NOAA National Centers for Environmental Information. https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2016JC011716TBA. Accessed [date].',\n",
       "  'summary': 'Global Drifter Program hourly data'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.layout.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d9b844-7bcd-417c-b82f-897a81bcae44",
   "metadata": {},
   "source": [
    "### variable attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "025cb485-b579-44cf-a8bb-4ad8fa95c6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attrs': {'long_name': 'Global Drifter Program Buoy ID', 'units': '-'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.ID.layout.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46e066ea-abbc-440e-962d-2e81cb66a2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attrs': {'long_name': 'Fitted sea water temperature',\n",
       "  'units': 'Kelvin',\n",
       "  'comments': 'Estimated near-surface sea water temperature from drifting buoy measurements. It is the sum of the fitted near-surface non-diurnal sea water temperature and fitted diurnal sea water temperature anomaly. Discrepancies may occur because of rounding.'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.obs.sst.layout.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ff8420-28be-43bc-b2ff-2960bca2f8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clouddrift",
   "language": "python",
   "name": "clouddrift"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
