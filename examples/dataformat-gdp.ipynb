{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6426c30b-df03-46a9-8fb7-57ddf404683e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Global Drifter Program (GDP)\n",
    "\n",
    "As part of this Notebook, we will use the *GDP historical dataset* to highlight the required steps to preprocess and dataset into a format that can be ingest by the *CloudDrift* library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d4c013-74b6-4444-828c-b74d6231141a",
   "metadata": {},
   "source": [
    "## Dataformat module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5e2a1a-2e8c-464f-8075-357c9b8313c2",
   "metadata": {},
   "source": [
    "The `dataformat.py` module contains the class `create_ragged_array` to transform a series of archives into an *Awkward Array* where all variables is stored as a *ragged array*. The module also contains `read_from_netcdf` and `read_from_parquet` to initialize the *Awkward Array* directly from an previously preprocessed archive. Right now, it *only* supports local array but we will soon add the possibility of *lazy-loading* array stored in the Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cca829b-f96f-4e09-bfbc-d7b2ec2d008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af3634f-be14-43af-8092-8be2c95ebc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../')\n",
    "from clouddrift import dataformat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665b9136-d79f-49e7-9bf8-12ea494cf196",
   "metadata": {},
   "source": [
    "The main class of this module is *create_ragged_array* and is used to create a single archive that can be saved to a netCDF or Parquet file. The signature of the class is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c32a79-e643-45d4-810f-f93d923e5d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataformat.create_ragged_array?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aded949-7d07-47fd-b184-50574c2600ba",
   "metadata": {},
   "source": [
    "## Dataset-specific functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c133b096-ee61-4018-b797-d43cc9db7329",
   "metadata": {},
   "source": [
    "Since each dataset is different, we have to create specific functions to preprocess the dataset (`preprocess_func`) and return the metadata and data of a single trajectory. This was inspired by the [Pangeo Forge](https://pangeo-forge.readthedocs.io/en/latest/) project. The class *create_ragged_array* will use those functions to create the single archive of ragged arrays. More precisely, it requires:\n",
    "- a list of indices (or identification number) that will be concatenate into the ragged array format\n",
    "- a preprecessing function with the following signature:\n",
    "    - `Signature: preprocess_func(index: int) -> xarray.core.dataset.Dataset`, where the index parameter is an identifier of a trajectory, e.g. the identification number of an Argo float) and returns an *xarray Dataset*. \n",
    "- a dictionnary mapping the mandatory coordinates list to the name of those variables in the dataset, e.g.\n",
    "    coords = {'ids': 'number', 'time': 't', 'longitude': 'lon', 'latitude': 'lat'}\n",
    "- an optional list of variable names containing metadata information about the trajectory (size: 1 per trajectory)\n",
    "- an optional list of variable names containing the data along the trajectory (size: number of observations per trajectory)\n",
    "- an optional funcition that returns directly the number of observation of a trajectory (`Signature: rowsize_func(index: int) -> int`)\n",
    "    \n",
    "This function can performs all type of operations, such as formatting the date, changing the type of variables, modifying the metadata, etc. We provide preprocessing function for different datasets in the `data/recipes/` folder. The class also needs to *initially* calculate the sum of all observations. By default, this is performed using `lambda i: preprocess_func(i).dims['obs']`. To *speed up* this process, in the situation where a lot of preprocessing are performed, it is possible to provide a second function `rowsize_func`, that returns directly the number of observation of a trajectory (`Signature: rowsize_func(index: int) -> int`)\n",
    "\n",
    "Finally, we import the gdp module which contains a function to download (or update) and preprocess the GDP dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aa29c2-5cfa-4ca7-ada3-7c3a6ec3b384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import gdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42a0c03-fcb3-4131-af3c-e6e7bea4e833",
   "metadata": {},
   "source": [
    "# Download\n",
    "\n",
    "The download function will store the raw dataset into the `data/raw/` folder specified in the `gdp.py` module. By default `download_gdp_data()` will download the complete GPD dataset (containing 17,324 files as of May 2022) from the AOML `https` server.\n",
    "\n",
    "**Note**: this Notebook is very similar to the `data-glad.ipynb` Notebook because very few functions have to be created to transform a new dataset. We hope that this will encourage people to use this dataformat and utilize the CloudDrift library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff938826-a6af-4e18-b8b1-39d236c92608",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp.download?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d977de-6162-4f63-b576-e9377d1d4f3e",
   "metadata": {},
   "source": [
    "It is possible to prodive a list of `drifter_ids` to retrieve a subset and/or specified a integer `n_random_id` to randomly retrieve `n` trajectory. The function returns the list of `drifters_ids` that was downloaded, and can be passed to create the ragged array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b162c91d-fc2a-4a86-9a0d-361e3af89b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "drifter_ids = gdp.download(n_random_id=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35f6f75-f7fb-4ba3-814f-46e3b8cc7d34",
   "metadata": {},
   "source": [
    "Once the data downloaded, it is possible to create the ragged array and either save a netCDF, parquet file, or simply output an Awkward Array that can be used for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59137333-eed9-406f-8af2-e3a782fad210",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = {'ids': 'ids', 'time': 'time', 'lon': 'longitude', 'lat': 'latitude'}\n",
    "metadata = ['ID', 'rowsize', 'WMO', 'expno', 'deploy_date', 'deploy_lat', 'deploy_lon', 'end_date', 'end_lat', 'end_lon', 'drogue_lost_date', 'typedeath', 'typebuoy', 'location_type', 'DeployingShip', 'DeploymentStatus', 'BuoyTypeManufacturer', 'BuoyTypeSensorArray', 'CurrentProgram', 'PurchaserFunding', 'SensorUpgrade', 'Transmissions', 'DeployingCountry', 'DeploymentComments', 'ManufactureYear', 'ManufactureMonth', 'ManufactureSensorType', 'ManufactureVoltage', 'FloatDiameter', 'SubsfcFloatPresence', 'DrogueType', 'DrogueLength', 'DrogueBallast', 'DragAreaAboveDrogue', 'DragAreaOfDrogue', 'DragAreaRatio', 'DrogueCenterDepth', 'DrogueDetectSensor']\n",
    "data = ['ve', 'vn', 'err_lat', 'err_lon', 'err_ve', 'err_vn', 'gap', 'sst', 'sst1', 'sst2', 'err_sst', 'err_sst1', 'err_sst2', 'flg_sst', 'flg_sst1', 'flg_sst2', 'drogue_status']\n",
    "\n",
    "ra = dataformat.create_ragged_array(drifter_ids,\n",
    "                         gdp.preprocess,\n",
    "                         coords, \n",
    "                         metadata, \n",
    "                         data,\n",
    "                         rowsize_func=gdp.rowsize\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00705eef-eb9b-4cdd-958d-e9afb832e7f0",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e377c2-2fba-4378-8c77-4f6747fa51f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ra.to_parquet('../data/process/gdp_v2.00.parquet')\n",
    "ra.to_netcdf('../data/process/gdp_v2.00.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9048e0-fc3b-49ec-b35b-285fbecda8e5",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821a999d-ee63-4087-92e8-5373d5c61b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = dataformat.read_from_parquet('../data/process/gdp_v2.00.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2f211d-7217-4964-bbe8-b47d93533ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2.ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcf518d-1f87-44ae-a284-7a4b34950bbc",
   "metadata": {},
   "source": [
    "## Awkward Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d885008c-c033-4532-a356-10055ae774a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward._v2 as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7334d731-4bfd-4e29-9196-bd68953df007",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ra.to_awkward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2b66fb-beb6-4316-8af1-b14a6029e3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.nanmean(ds.obs.err_lat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b48833-387a-4fe7-a144-1e1628959ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b78c8a-177b-4842-a8c9-9f98daaa27e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.obs.fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2848fc27-2151-40e3-9dda-6746df5a2ec6",
   "metadata": {},
   "source": [
    "### global attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfc0238-1bab-4bf4-994d-459231fb5f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.layout.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d9b844-7bcd-417c-b82f-897a81bcae44",
   "metadata": {},
   "source": [
    "### variable attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025cb485-b579-44cf-a8bb-4ad8fa95c6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.ID.layout.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e066ea-abbc-440e-962d-2e81cb66a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.obs.sst.layout.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ff8420-28be-43bc-b2ff-2960bca2f8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clouddrift",
   "language": "python",
   "name": "clouddrift"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
