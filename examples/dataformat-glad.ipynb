{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6426c30b-df03-46a9-8fb7-57ddf404683e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CARTHE Glad Experiment\n",
    "\n",
    "As part of this Notebook, we will use the *CARTHE GLAD experiment dataset* to highlight the required steps to preprocess and dataset into a format that can be ingest by the *CloudDrift* library.\n",
    "\n",
    "**Note**: this Notebook is very similar to the `data-gdp.ipynb` Notebook because very few functions have to be created to transform a new dataset. We hope that this will encourage people to use this dataformat and utilize the CloudDrift library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d4c013-74b6-4444-828c-b74d6231141a",
   "metadata": {},
   "source": [
    "## Dataformat module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5e2a1a-2e8c-464f-8075-357c9b8313c2",
   "metadata": {},
   "source": [
    "The `dataformat.py` module contains the class `create_ragged_array` to transform a series of archives into an *Awkward Array* where all variables is stored as a *ragged array*. The module also contains `read_from_netcdf` and `read_from_parquet` to initialize the *Awkward Array* directly from an previously preprocessed archive. Right now, it *only* supports local array but we will soon add the possibility of *lazy-loading* array stored in the Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cca829b-f96f-4e09-bfbc-d7b2ec2d008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from clouddrift import dataformat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665b9136-d79f-49e7-9bf8-12ea494cf196",
   "metadata": {},
   "source": [
    "The main class of this module is *create_ragged_array* and is used to create a single archive that can be saved to a netCDF or Parquet file. The signature of the class is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c32a79-e643-45d4-810f-f93d923e5d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataformat.create_ragged_array?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aded949-7d07-47fd-b184-50574c2600ba",
   "metadata": {},
   "source": [
    "## Dataset-specific functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c133b096-ee61-4018-b797-d43cc9db7329",
   "metadata": {},
   "source": [
    "Since each dataset is different, we have to create specific functions to preprocess the dataset (`preprocess_func`) and return the metadata and data of a single trajectory. This was inspired by the [Pangeo Forge](https://pangeo-forge.readthedocs.io/en/latest/) project. The class *create_ragged_array* will use those functions to create the single archive of ragged arrays. More precisely, it requires:\n",
    "- a list of indices (or identification number) that will be concatenate into the ragged array format\n",
    "- a preprecessing function with the following signature:\n",
    "    - `Signature: preprocess_func(index: int) -> xarray.core.dataset.Dataset`, where the index parameter is an identifier of a trajectory, e.g. the identification number of an Argo float) and returns an *xarray Dataset*. \n",
    "- a dictionnary mapping the mandatory coordinates list to the name of those variables in the dataset, e.g.\n",
    "    coords = {'ids': 'number', 'time': 't', 'longitude': 'lon', 'latitude': 'lat'}\n",
    "- an optional list of variable names containing metadata information about the trajectory (size: 1 per trajectory)\n",
    "- an optional list of variable names containing the data along the trajectory (size: number of observations per trajectory)\n",
    "- an optional funcition that returns directly the number of observation of a trajectory (`Signature: rowsize_func(index: int) -> int`)\n",
    "    \n",
    "This function can performs all type of operations, such as formatting the date, changing the type of variables, modifying the metadata, etc. We provide preprocessing function for different datasets in the `data/recipes/` folder. The class also needs to *initially* calculate the sum of all observations. By default, this is performed using an lambda function: `lambda i: self.preprocess_func(i).dims['obs']`. To *speed up* this process, in the situation where a lot of preprocessing are performed, it is possible to provide a function `rowsize_func`, that returns directly the number of observation of a trajectory (`Signature: rowsize_func(index: int) -> int`)\n",
    "\n",
    "Because there is only one `dat` file, it is automatically loaded when importing the module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aa29c2-5cfa-4ca7-ada3-7c3a6ec3b384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import glad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42a0c03-fcb3-4131-af3c-e6e7bea4e833",
   "metadata": {},
   "source": [
    "We can test the preprocessing function by calling it with one of the identification numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2db0565-359a-4538-a2b0-33c195b72d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "glad.preprocess(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35f6f75-f7fb-4ba3-814f-46e3b8cc7d34",
   "metadata": {},
   "source": [
    "It is now possible to create the ragged array and either save a netCDF, parquet file, or simply output an Awkward Array that can be used for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59137333-eed9-406f-8af2-e3a782fad210",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [  1,   2,   3,   4,   5,   6,   7,   8,  10,  11,  12,  13,  14,\n",
    "        15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
    "        28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,\n",
    "        41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  52,  53,  54,\n",
    "        55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,\n",
    "        68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,\n",
    "        83,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,\n",
    "        97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
    "       110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,\n",
    "       123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135,\n",
    "       136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,\n",
    "       149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161,\n",
    "       162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174,\n",
    "       175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187,\n",
    "       188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200,\n",
    "       201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213,\n",
    "       214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226,\n",
    "       227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
    "       240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
    "       253, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266,\n",
    "       267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
    "       280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 301, 302,\n",
    "       303, 304, 306, 307, 308, 310, 313, 314, 315, 317, 451]\n",
    "\n",
    "coords = {'ids': 'ids', 'time': 'time', 'lon': 'longitude', 'lat': 'latitude'}\n",
    "metadata = ['ID', 'rowsize']\n",
    "data = ['ve', 'vn', 'err_pos', 'err_vel']\n",
    "\n",
    "ra = dataformat.create_ragged_array(files,\n",
    "                         glad.preprocess,\n",
    "                         coords,\n",
    "                         metadata, \n",
    "                         data,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00705eef-eb9b-4cdd-958d-e9afb832e7f0",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e377c2-2fba-4378-8c77-4f6747fa51f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra.to_parquet('../data/process/glad.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7334d731-4bfd-4e29-9196-bd68953df007",
   "metadata": {},
   "outputs": [],
   "source": [
    "ak = ra.to_awkward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b33d76b-f937-4f89-b8c2-64712355b8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d16a880-de6a-4edb-8618-d8d346c478b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df468219-de23-49be-bb00-b745f3ed606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.obs.fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d88f4e-56d3-476c-8bc9-0ee50588a809",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d608c0-d705-4002-8ef8-6f9dcddeb8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ak2 = dataformat.read_from_parquet('../data/process/glad.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3baeb7-bee4-420d-82ff-983a547e2bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ak2.ID"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clouddrift",
   "language": "python",
   "name": "clouddrift"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
